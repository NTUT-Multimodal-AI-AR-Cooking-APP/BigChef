import UIKit
import Vision
import CoreML
import ARKit

/// å–®ä¾‹ï¼Œç”¨æ–¼ 2D ç‰©ä»¶åµæ¸¬ä¸¦ç¹ªè£½åœ¨ overlayView ä¸Š
class ObjectDetector {
    static let shared = ObjectDetector()

    private weak var overlayView: UIView?
    private var boxLayers = [CAShapeLayer]()
    private var textLayers = [CATextLayer]()
    private let vnModel: VNCoreMLModel

    private init() {
        do {
            let coreMLModel = try CookDetect(configuration: MLModelConfiguration()).model
            vnModel = try VNCoreMLModel(for: coreMLModel)
        } catch {
            fatalError("âŒ ç„¡æ³•è¼‰å…¥ CookDetect æ¨¡å‹ï¼š\(error)")
        }
    }

    /// è¨­å®šç”¨æ–¼ç¹ªè£½åµæ¸¬çµæœçš„ Overlay
    func configure(overlay: UIView) {
        overlayView = overlay
    }

    /// æ¸…é™¤æ‰€æœ‰èˆŠçš„ç¹ªè£½ Layer
    func clear() {
        boxLayers.forEach { $0.removeFromSuperlayer() }
        textLayers.forEach { $0.removeFromSuperlayer() }
        boxLayers.removeAll()
        textLayers.removeAll()
    }

    /// åµæ¸¬æŒ‡å®šå®¹å™¨ï¼Œå›å‚³ (boundingRect, label, confidence) æˆ– nil
    func detectContainer(target container: Container,
                         in pixelBuffer: CVPixelBuffer,
                         completion: @escaping ((CGRect, String, Float)?) -> Void)
    {
        let request = VNCoreMLRequest(model: vnModel) { [weak self] request, error in
            guard let self = self else { completion(nil); return }
            if let error = error {
                print("ğŸ›‘ VNCoreMLRequest éŒ¯èª¤ï¼š\(error)")
                completion(nil)
                return
            }

            // åªå–ç¬¬ä¸€å€‹ç¬¦åˆ container label çš„åµæ¸¬çµæœ
            let observations = (request.results as? [VNRecognizedObjectObservation]) ?? []
            for obs in observations {
                guard let top = obs.labels.first,
                      top.identifier == container.rawValue,
                      let overlay = self.overlayView
                else { continue }

                let box = obs.boundingBox
                let viewW = overlay.bounds.width
                let viewH = overlay.bounds.height

                let x = box.minX * viewW
                let w = box.width * viewW
                // Vision çš„ y åŸé»åœ¨åº•éƒ¨ï¼ŒUIKit åœ¨é ‚éƒ¨ï¼Œæ‰€ä»¥ç”¨ (1 - maxY)
                let y = (1 - box.maxY) * viewH
                let h = box.height * viewH

                let viewRect = CGRect(x: x, y: y, width: w, height: h)

                // åœ¨ä¸»ç·šç¨‹ç¹ªè£½
                DispatchQueue.main.async {
                    
                    self.clear()
/*
                    // 1. Bounding box
                    let boxLayer = CAShapeLayer()
                    boxLayer.frame = overlay.bounds
                    boxLayer.path      = UIBezierPath(rect: viewRect).cgPath
                    boxLayer.strokeColor = UIColor.systemRed.cgColor
                    boxLayer.fillColor   = UIColor.clear.cgColor   // â† æ¸…é™¤é è¨­é»‘è‰²å¡«å……
                    boxLayer.lineWidth   = 2
                    overlay.layer.addSublayer(boxLayer)
                    self.boxLayers.append(boxLayer)

                    // 2. Label + confidence
                    let textLayer = CATextLayer()
                    textLayer.string          = "\(top.identifier) \(Int(top.confidence * 100))%"
                    textLayer.fontSize        = 14
                    textLayer.alignmentMode   = .center
                    textLayer.foregroundColor = UIColor.white.cgColor
                    textLayer.backgroundColor = UIColor.black.withAlphaComponent(0.6).cgColor
                    textLayer.frame = CGRect(
                        x: viewRect.minX,
                        y: viewRect.minY - 22,
                        width: viewRect.width,
                        height: 20
                    )
                    textLayer.contentsScale = UIScreen.main.scale
                    overlay.layer.addSublayer(textLayer)
                    self.textLayers.append(textLayer)*/
                }

                // å›å‚³ç•«åœ¨ overlay ä¸Šçš„ viewRect
                completion((viewRect, top.identifier, top.confidence))
                return
            }

            // æ²’åµæ¸¬åˆ°
            completion(nil)
        }

        // è¨˜å¾—å¸¶ä¸Š orientation æ‰ä¸æœƒå› ç‚ºç•«é¢æ—‹è½‰å°è‡´æ¡†ä¸å°é½Š
        let handler = VNImageRequestHandler(
            cvPixelBuffer: pixelBuffer,
            orientation: .right,  // æˆ–æ ¹æ“šä½ çš„ ARView ç•«é¢æ–¹å‘èª¿æ•´
            options: [:]
        )
        DispatchQueue.global(qos: .userInitiated).async {
            do {
                try handler.perform([request])
            } catch {
                print("ğŸ›‘ VNImageRequestHandler éŒ¯èª¤ï¼š\(error)")
                completion(nil)
                
            }
        }
    }
}

